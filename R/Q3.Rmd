---
title: "Q3"
author: "Gowtham P" 
output: html_document
---

3.	Using the "Online Retail" dataset, complete the following tasks with appropriate analysis and interpretation:

```{r}
library(dplyr)
library(readxl)
library(ggplot2)
```
i. Why is data cleaning important in the dataset, and what impact does filtering out transactions with Quantity <= 0 and UnitPrice <= 0, missing CustomerID, and removing observations from December 2011 in the InvoiceDate column have on the dataset's validity for analysis?

```{r}
#### 1. Load Data ####
df <- read_excel("D:/Data Science for Marketing-I& 2/dataset/Online Retail.xlsx")
```

```{r}
# ignore negative quantity
dim(df)
df <- df[which(df$Quantity > 0),]
dim(df)
```

```{r}
# remove records with NA
df <- na.omit(df)
dim(df)
```

```{r}
# excluding incomplete month
sprintf("Date Range: %s ~ %s", min(df$InvoiceDate), max(df$InvoiceDate))
dim(df)
df <- df[which(df$InvoiceDate < '2011-12-01'),]
dim(df)
```
Interpertation:

Removing invalid transactions and missing customer data improves dataset reliability.

ii. What role does the newly created Sales based on Quantity and UnitPrice columns play in customer behavior analysis?

```{r}
# total sales
df$Sales <- df$Quantity * df$UnitPrice
```
Interpertation:

Sales help in understanding customer spending patterns and revenue contribution.

iii. Create orderDF by grouping transactions based on CustomerID and InvoiceNo, and visualize customer behavior based on purchase frequency and total sales.

```{r}
ordersDF <- df %>% 
  group_by(CustomerID, InvoiceNo) %>% 
  summarize(Sales = sum(Sales), InvoiceDate = max(InvoiceDate), .groups = "drop")

```

```{r}
# order amount & frequency summary
summaryDF <- ordersDF %>%
  group_by(CustomerID) %>%
  summarize(
    SalesMin=min(Sales), SalesMax=max(Sales), SalesSum=sum(Sales), SalesAvg=mean(Sales), SalesCount=n(),
    InvoiceDateMin=min(InvoiceDate), InvoiceDateMax=max(InvoiceDate), 
    PurchaseDuration=as.double(floor(max(InvoiceDate)-min(InvoiceDate))),
    PurchaseFrequency=as.double(floor(max(InvoiceDate)-min(InvoiceDate)))/n()
  )
```

```{r}
# customers with repeat purchases
dim(summaryDF)
```

```{r}
summaryDF <- summaryDF[which(summaryDF$PurchaseDuration > 0),]
dim(summaryDF)
```

```{r}
salesCount <- summaryDF %>% 
  group_by(SalesCount) %>% 
  summarize(Count=n())
```

```{r}
ggplot(salesCount[1:19,], aes(x=SalesCount, y=Count)) +
  geom_bar(width=0.5, stat="identity") +
  ggtitle('') +
  xlab("Sales Count") +
  ylab("Count") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
summary(summaryDF$SalesCount)
```

```{r}
summary(summaryDF$SalesAvg)
```

```{r}
hist(
  summaryDF$PurchaseFrequency, 
  breaks=20,
  xlab='avg. number of days between purchases',
  ylab='count',
  main=''
)
```

```{r}
summary(summaryDF$PurchaseDuration)
```

```{r}
summary(summaryDF$PurchaseFrequency)
```
Interpertation:

This visualization highlights frequent buyers and overall purchase trends.

iv. Prepare data for model building by creating five quarters, using four quarters as features and the latest quarter as the response variable.


```{r}
# group data into every 3 months
library(lubridate)
```


```{r}
ordersDF$Quarter = as.character(round_date(ordersDF$InvoiceDate, '3 months'))

dataDF <- ordersDF %>%
  group_by(CustomerID, Quarter) %>%
  summarize(SalesSum = sum(Sales), SalesAvg = mean(Sales), SalesCount = n(), .groups = "drop")

dataDF$Quarter[dataDF$Quarter == "2012-01-01"] <- "Q1"
dataDF$Quarter[dataDF$Quarter == "2011-10-01"] <- "Q2"
dataDF$Quarter[dataDF$Quarter == "2011-07-01"] <- "Q3"
dataDF$Quarter[dataDF$Quarter == "2011-04-01"] <- "Q4"
dataDF$Quarter[dataDF$Quarter == "2011-01-01"] <- "Q5"

```


# building sample set
```{r}
# install.packages('reshape2')
library(reshape2)
```

```{r}
salesSumFeaturesDF <- dcast(
  dataDF[which(dataDF$Quarter != "Q1"),], 
  CustomerID ~ Quarter, 
  value.var="SalesSum"
)
colnames(salesSumFeaturesDF) <- c("CustomerID", "SalesSum.Q2", "SalesSum.Q3", "SalesSum.Q4", "SalesSum.Q5")


salesAvgFeaturesDF <- dcast(
  dataDF[which(dataDF$Quarter != "Q1"),], 
  CustomerID ~ Quarter, 
  value.var="SalesAvg"
)
colnames(salesAvgFeaturesDF) <- c("CustomerID", "SalesAvg.Q2", "SalesAvg.Q3", "SalesAvg.Q4", "SalesAvg.Q5")

salesCountFeaturesDF <- dcast(
  dataDF[which(dataDF$Quarter != "Q1"),], 
  CustomerID ~ Quarter, 
  value.var="SalesCount"
)
colnames(salesCountFeaturesDF) <- c("CustomerID", "SalesCount.Q2", "SalesCount.Q3", "SalesCount.Q4", "SalesCount.Q5")

featuresDF <- merge(
  merge(salesSumFeaturesDF, salesAvgFeaturesDF, by="CustomerID"),
  salesCountFeaturesDF, by="CustomerID"
)
featuresDF[is.na(featuresDF)] <- 0

responseDF <- dataDF[which(dataDF$Quarter == "Q1"),] %>% 
  select(CustomerID, SalesSum)
colnames(responseDF) <- c("CustomerID", "CLV_3_Month")

sampleDF <- merge(featuresDF, responseDF, by="CustomerID", all.x=TRUE)
sampleDF[is.na(sampleDF)] <- 0

summary(sampleDF$CLV_3_Month)
```
Interpertation:

Sales data is structured for predictive modeling using past quarters as features.

v. Build a regression model using the linear regression algorithm and interpret the model summary.


```{r}
# train/test set split
library(caTools)
```

```{r}
sample <- sample.split(sampleDF$CustomerID, SplitRatio = .8)

train <- as.data.frame(subset(sampleDF, sample == TRUE))[,-1]
test <- as.data.frame(subset(sampleDF, sample == FALSE))[,-1]
```

```{r}
# Linear Regression model
regFit <- lm(CLV_3_Month ~ ., data=train)

summary(regFit)
```
Interpertation:

The model determines how past sales patterns influence future revenue.

vi.Predict values for the training and test data, and evaluate its performance using all possibleÂ metrics.

```{r}
## 4.3. Evaluation ##
train_preds <- predict(regFit, train)
test_preds <- predict(regFit, test)
```
# R-squared
```{r}
# install.packages('miscTools')
library(miscTools)
```

```{r}
inSampleR2 <- rSquared(train$CLV_3_Month, resid=train$CLV_3_Month - train_preds)
outOfSampleR2 <- rSquared(test$CLV_3_Month, resid=test$CLV_3_Month - test_preds)

sprintf('In-Sample R-Squared: %0.4f', inSampleR2)
sprintf('Out-of-Sample R-Squared: %0.4f', outOfSampleR2)
```

```{r}
# Median Absolute Error
inSampleMAE <- median(abs(train$CLV_3_Month - train_preds))
outOfSampleMAE <- median(abs(test$CLV_3_Month - test_preds))

sprintf('In-Sample MAE: %0.4f', inSampleMAE)
sprintf('Out-of-Sample MAE: %0.4f', outOfSampleMAE)
```

```{r}
# Actual vs. Predicted Scatter Plot
plot(
  train$CLV_3_Month, 
  train_preds, 
  xlab='actual', 
  ylab='predicted', 
  main='In-Sample Actual vs. Predicted'
)
abline(a=0, b=1)

plot(
  test$CLV_3_Month, 
  test_preds, 
  xlab='actual', 
  ylab='predicted', 
  main='Out-of-Sample Actual vs. Predicted'
)
abline(a=0, b=1)
```
Interpertation:

 MAE evaluate prediction accuracy, ensuring the model's effectiveness.